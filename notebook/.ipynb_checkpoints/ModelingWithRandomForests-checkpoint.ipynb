{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Parallelism with Machine Learning: The Housing Prices Competition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the competition\n",
    "\n",
    "- The Housing Prices Competition train_dataset consists of various features of residential homes in Ames, Iowa, including both quantitative and categorical variables like the size of the property, the number of rooms, year built, and neighborhood quality.\n",
    "- It includes a set of 79 explanatory variables describing almost every aspect of the houses, allowing for in-depth analysis.\n",
    "- *The primary goal* of the competition is to predict **the final price of each home**, in this lab we will use *RandomForests*.\n",
    "- The models are evaluated on Root Mean Squared Error (RMSE) between the logarithm of the predicted value and the logarithm of the observed sales price, encouraging precise predictions over a range of housing prices.\n",
    "\n",
    "### File descriptions\n",
    "- *train.csv*: the training set used to train the model.\n",
    "- *test.csv*: the test set used to compute the performance of the model.\n",
    "- *train_data_description.txt*: full description of each column.\n",
    "### Useful train_data fields\n",
    "\n",
    "Here's a brief version of what you'll find in the train_data description file.\n",
    "\n",
    "- *SalePrice*: the property's sale price in dollars. This is the target variable that you're trying to predict.\n",
    "- *MSSubClass*: The building class\n",
    "- *MSZoning*: The general zoning classification\n",
    "\n",
    "Teh train_dataset is acessible here: https://www.kaggle.com/code/dansbecker/random-forests/tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and prepare the train_data\n",
    "*If you're curious about this the professor can explain it for you*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The file 'data/train.csv' was not found. Please check the file path and try again.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m columns_to_delete \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMoSold\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYrSold\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaleType\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSaleCondition\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlley\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFireplaceQu\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPoolQC\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFence\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMiscFeature\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Delete the specified columns\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m train_data_cleaned \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39mcolumns_to_delete, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Define the input features (X) and the output (y)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m X \u001b[38;5;241m=\u001b[39m train_data_cleaned\u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSalePrice\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import itertools\n",
    "import threading\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Load the train dataset\n",
    "file_path = 'data/train.csv'\n",
    "try:\n",
    "    train_data = pd.read_csv(file_path, index_col=\"Id\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{file_path}' was not found. Please check the file path and try again.\")\n",
    "    exit()\n",
    "\n",
    "# Columns to be deleted\n",
    "columns_to_delete = ['MoSold', 'YrSold', 'SaleType', 'SaleCondition', 'Alley', 'FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature']\n",
    "\n",
    "# Delete the specified columns\n",
    "train_data_cleaned = train_data.drop(columns=columns_to_delete, axis=1, errors='ignore')\n",
    "\n",
    "# Define the input features (X) and the output (y)\n",
    "X = train_data_cleaned.drop('SalePrice', axis=1)\n",
    "y = train_data_cleaned['SalePrice']\n",
    "\n",
    "# Identify the categorical columns in X\n",
    "categorical_columns = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Apply Label Encoding to each categorical column\n",
    "for column in categorical_columns:\n",
    "    X[column] = X[column].astype('category').cat.codes\n",
    "\n",
    "# Define the parameter ranges\n",
    "n_estimators_range = [10, 25, 50, 100, 200, 300, 400]\n",
    "max_features_range = ['sqrt', 'log2', None]  # None means using all features\n",
    "max_depth_range = [1, 2, 5, 10, 20, None]  # None means no limit\n",
    "\n",
    "# Shared variables to store the best model and parameters\n",
    "best_rmse = float('inf')\n",
    "best_mape = float('inf')\n",
    "best_model = None\n",
    "best_parameters = {}\n",
    "lock = threading.Lock()  # To synchronize access to shared resources\n",
    "\n",
    "def evaluate_model(params):\n",
    "    global best_rmse, best_mape, best_model, best_parameters\n",
    "    n_estimators, max_features, max_depth = params\n",
    "    \n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X, y)\n",
    "    y_val_pred = rf_model.predict(X)\n",
    "    \n",
    "    rmse = sqrt(mean_squared_error(y, y_val_pred))\n",
    "    mape = mean_absolute_percentage_error(y, y_val_pred) * 100\n",
    "    \n",
    "    with lock:  # Ensure only one thread/process updates the best model at a time\n",
    "        if rmse < best_rmse:\n",
    "            best_rmse = rmse\n",
    "            best_mape = mape\n",
    "            best_model = rf_model\n",
    "            best_parameters = {\n",
    "                'n_estimators': n_estimators,\n",
    "                'max_features': max_features,\n",
    "                'max_depth': max_depth\n",
    "            }\n",
    "    print(f\"Params: {params} -> RMSE: {rmse}, MAPE: {mape}%\")\n",
    "\n",
    "# Generate all parameter combinations\n",
    "param_combinations = list(itertools.product(n_estimators_range, max_features_range, max_depth_range))\n",
    "\n",
    "# Parallel execution using threading\n",
    "start_time = time.time()\n",
    "threads = []\n",
    "for params in param_combinations:\n",
    "    thread = threading.Thread(target=evaluate_model, args=(params,))\n",
    "    threads.append(thread)\n",
    "    thread.start()\n",
    "\n",
    "for thread in threads:\n",
    "    thread.join()\n",
    "\n",
    "threading_time = time.time() - start_time\n",
    "print(f\"Threading execution time: {threading_time:.2f} seconds\")\n",
    "print(f\"Best Parameters: {best_parameters}, Best RMSE: {best_rmse}, Best MAPE: {best_mape}%\")\n",
    "\n",
    "# Reset best values for multiprocessing\n",
    "best_rmse = float('inf')\n",
    "best_mape = float('inf')\n",
    "best_model = None\n",
    "best_parameters = {}\n",
    "\n",
    "# Parallel execution using multiprocessing\n",
    "start_time = time.time()\n",
    "with multiprocessing.Pool(processes=multiprocessing.cpu_count()) as pool:\n",
    "    pool.map(evaluate_model, param_combinations)\n",
    "\n",
    "multiprocessing_time = time.time() - start_time\n",
    "print(f\"Multiprocessing execution time: {multiprocessing_time:.2f} seconds\")\n",
    "print(f\"Best Parameters: {best_parameters}, Best RMSE: {best_rmse}, Best MAPE: {best_mape}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the Data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Split the first dataset (X, y) into train and test sets with a 70% - 30% split\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m X_train, X_val, y_train, y_val \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.30\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Fill NaN values in X_train and X_val with the median of the respective columns\u001b[39;00m\n\u001b[1;32m      7\u001b[0m X_train_filled \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mfillna(X_train\u001b[38;5;241m.\u001b[39mmedian())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the first dataset (X, y) into train and test sets with a 70% - 30% split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "# Fill NaN values in X_train and X_val with the median of the respective columns\n",
    "X_train_filled = X_train.fillna(X_train.median())\n",
    "X_val_filled = X_val.fillna(X_val.median())\n",
    "\n",
    "(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First RandomForest Model\n",
    "This is the code for a simple trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on the validation data: 26057.941851126383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Create a Random Forest model\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model on the training data\n",
    "rf_model.fit(X_train_filled, y_train)\n",
    "\n",
    "# Make predictions on the validation data\n",
    "y_val_pred_filled = rf_model.predict(X_val_filled)\n",
    "\n",
    "# Calculate the RMSE on the validation data\n",
    "rmse_filled = sqrt(mean_squared_error(y_val, y_val_pred_filled))\n",
    "\n",
    "# Print the RMSE\n",
    "print(f'RMSE on the validation data: {rmse_filled}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters of Random Forest Model\n",
    "The three most important parameters that typically have the most impact on the performance of a Random Forest model are:\n",
    "\n",
    "- *n_estimators*: This parameter specifies the number of trees in the forest. Generally, a higher number of trees increases the performance and makes the predictions more stable, but it also makes the computation slower. Selecting the right number of trees requires balancing between performance and computational efficiency.\n",
    "\n",
    "- *max_features*: This parameter defines the maximum number of features that are allowed to try in an individual tree. There are several options available for this parameter:\n",
    "\n",
    "    - *sqrt*: This is commonly used and means that the maximum number of features used at each split is the square root of the total number of features.\n",
    "    - *log2*: This is another typical option, meaning the log base 2 of the feature count is used.\n",
    "    - *A specific integer or float*: You can specify an exact number or a proportion of the total.\n",
    "\n",
    "- *max_depth*: This parameter specifies the maximum depth of each tree. Deeper trees can model more complex patterns, but they also risk overfitting. Limiting the depth of trees can improve the model's generalization and reduce overfitting. It's often useful to set this parameter to a finite value, especially when dealing with a large number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the best parameters sequentially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_filled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 33\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m max_depth \u001b[38;5;129;01min\u001b[39;00m max_depth_range:\n\u001b[1;32m     27\u001b[0m     rf_model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(\n\u001b[1;32m     28\u001b[0m         n_estimators\u001b[38;5;241m=\u001b[39mn_estimators,\n\u001b[1;32m     29\u001b[0m         max_features\u001b[38;5;241m=\u001b[39mmax_features,\n\u001b[1;32m     30\u001b[0m         max_depth\u001b[38;5;241m=\u001b[39mmax_depth,\n\u001b[1;32m     31\u001b[0m         random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     32\u001b[0m     )\n\u001b[0;32m---> 33\u001b[0m     rf_model\u001b[38;5;241m.\u001b[39mfit(X_train_filled, y_train)\n\u001b[1;32m     35\u001b[0m     y_val_pred \u001b[38;5;241m=\u001b[39m rf_model\u001b[38;5;241m.\u001b[39mpredict(X_val_filled)\n\u001b[1;32m     36\u001b[0m     rmse \u001b[38;5;241m=\u001b[39m sqrt(mean_squared_error(y_val, y_val_pred))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train_filled' is not defined"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import threading\n",
    "import multiprocessing\n",
    "from math import sqrt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Define parameter ranges\n",
    "n_estimators_range = [10, 25, 50, 100, 200, 300, 400]\n",
    "max_features_range = ['sqrt', 'log2', None]\n",
    "max_depth_range = [1, 2, 5, 10, 20, None]\n",
    "\n",
    "# Get the number of CPU cores\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "\n",
    "# -------------------- SEQUENTIAL EXECUTION --------------------\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize best model tracking\n",
    "best_rmse = float('inf')\n",
    "best_mape = float('inf')\n",
    "\n",
    "for n_estimators in n_estimators_range:\n",
    "    for max_features in max_features_range:\n",
    "        for max_depth in max_depth_range:\n",
    "            rf_model = RandomForestRegressor(\n",
    "                n_estimators=n_estimators,\n",
    "                max_features=max_features,\n",
    "                max_depth=max_depth,\n",
    "                random_state=42\n",
    "            )\n",
    "            rf_model.fit(X_train_filled, y_train)\n",
    "\n",
    "            y_val_pred = rf_model.predict(X_val_filled)\n",
    "            rmse = sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "            mape = mean_absolute_percentage_error(y_val, y_val_pred) * 100\n",
    "            print(f\"Sequential - {n_estimators}, {max_features}, {max_depth}. RMSE: {rmse}, MAPE: {mape}%\")\n",
    "\n",
    "end_time = time.time()\n",
    "sequential_time = end_time - start_time\n",
    "print(f\"\\nSequential Execution Time: {sequential_time:.2f} sec\")\n",
    "\n",
    "# -------------------- THREADING EXECUTION --------------------\n",
    "\n",
    "start_time = time.time()\n",
    "threads = []\n",
    "\n",
    "def train_and_evaluate(n_estimators, max_features, max_depth):\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train_filled, y_train)\n",
    "\n",
    "    y_val_pred = rf_model.predict(X_val_filled)\n",
    "    rmse = sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    mape = mean_absolute_percentage_error(y_val, y_val_pred) * 100\n",
    "    print(f\"Threading - {n_estimators}, {max_features}, {max_depth}. RMSE: {rmse}, MAPE: {mape}%\")\n",
    "\n",
    "# Create and start threads\n",
    "for n_estimators in n_estimators_range:\n",
    "    for max_features in max_features_range:\n",
    "        for max_depth in max_depth_range:\n",
    "            t = threading.Thread(target=train_and_evaluate, args=(n_estimators, max_features, max_depth))\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "\n",
    "# Wait for threads to complete\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "end_time = time.time()\n",
    "threading_time = end_time - start_time\n",
    "print(f\"\\nThreading Execution Time: {threading_time:.2f} sec\")\n",
    "\n",
    "# -------------------- MULTIPROCESSING EXECUTION --------------------\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "def train_and_evaluate_mp(params):\n",
    "    n_estimators, max_features, max_depth = params\n",
    "    rf_model = RandomForestRegressor(\n",
    "        n_estimators=n_estimators,\n",
    "        max_features=max_features,\n",
    "        max_depth=max_depth,\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train_filled, y_train)\n",
    "\n",
    "    y_val_pred = rf_model.predict(X_val_filled)\n",
    "    rmse = sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    mape = mean_absolute_percentage_error(y_val, y_val_pred) * 100\n",
    "    print(f\"Multiprocessing - {n_estimators}, {max_features}, {max_depth}. RMSE: {rmse}, MAPE: {mape}%\")\n",
    "\n",
    "if _name_ == '_main_':\n",
    "    pool = multiprocessing.Pool(processes=num_cores)\n",
    "    param_combinations = [(n, f, d) for n in n_estimators_range for f in max_features_range for d in max_depth_range]\n",
    "    pool.map(train_and_evaluate_mp, param_combinations)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    end_time = time.time()\n",
    "    multiprocessing_time = end_time - start_time\n",
    "    print(f\"\\nMultiprocessing Execution Time: {multiprocessing_time:.2f} sec\")\n",
    "\n",
    "# -------------------- SPEEDUP & EFFICIENCY CALCULATIONS --------------------\n",
    "\n",
    "# Amdahl's Law Speedup\n",
    "parallel_fraction = 0.9  # Assuming 90% of execution is parallelizable\n",
    "amdahl_speedup_threading = 1 / ((1 - parallel_fraction) + (parallel_fraction / num_cores))\n",
    "amdahl_speedup_multiprocessing = 1 / ((1 - parallel_fraction) + (parallel_fraction / num_cores))\n",
    "\n",
    "# Gustafson's Law Speedup\n",
    "gustafson_speedup_threading = (1 - parallel_fraction) + (parallel_fraction * num_cores)\n",
    "gustafson_speedup_multiprocessing = (1 - parallel_fraction) + (parallel_fraction * num_cores)\n",
    "\n",
    "# Actual Speedups (from measured execution times)\n",
    "actual_speedup_threading = sequential_time / threading_time\n",
    "actual_speedup_multiprocessing = sequential_time / multiprocessing_time\n",
    "\n",
    "# Efficiency Calculation\n",
    "efficiency_threading = actual_speedup_threading / num_cores\n",
    "efficiency_multiprocessing = actual_speedup_multiprocessing / num_cores\n",
    "\n",
    "# Print Speedup & Efficiency Results\n",
    "print(\"\\n### Speedup & Efficiency Calculations ###\")\n",
    "print(f\"Amdahl's Speedup (Threading): {amdahl_speedup_threading:.2f}\")\n",
    "print(f\"Amdahl's Speedup (Multiprocessing): {amdahl_speedup_multiprocessing:.2f}\")\n",
    "print(f\"Gustafson's Speedup (Threading): {gustafson_speedup_threading:.2f}\")\n",
    "print(f\"Gustafson's Speedup (Multiprocessing): {gustafson_speedup_multiprocessing:.2f}\")\n",
    "print(f\"Actual Speedup (Threading): {actual_speedup_threading:.2f}\")\n",
    "print(f\"Actual Speedup (Multiprocessing): {actual_speedup_multiprocessing:.2f}\")\n",
    "print(f\"Efficiency (Threading): {efficiency_threading:.2f}\")\n",
    "print(f\"Efficiency (Multiprocessing): {efficiency_multiprocessing:.2f}\")\n",
    "\n",
    "# -------------------- FINAL EXECUTION TIME COMPARISON --------------------\n",
    "\n",
    "print(\"\\n### Final Execution Time Comparison ###\")\n",
    "print(f\"Sequential Execution Time: {sequential_time:.2f} sec\")\n",
    "print(f\"Threading Execution Time: {threading_time:.2f} sec\")\n",
    "print(f\"Multiprocessing Execution Time: {multiprocessing_time:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
